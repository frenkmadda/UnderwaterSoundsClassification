{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "id": "416a82b8b7e1a503"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T17:52:25.740180Z",
     "start_time": "2024-06-29T17:52:25.713072Z"
    }
   },
   "source": [
    "def test_model_google(model_path, num_classes=2):\n",
    "    # Percorso al CSV (puoi definirlo qui)\n",
    "    csv_path = 'final_dataset/test/df_paths_test.csv'\n",
    "\n",
    "    # Funzione per caricare il modello\n",
    "    def load_model(model_path, device, num_classes):\n",
    "        model = models.googlenet(pretrained='imagenet')\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)  # Modifica il classificatore finale\n",
    "        model.aux1 = None  # Disabilita le teste ausiliarie\n",
    "        model.aux2 = None\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    # Funzione per caricare un'immagine e applicare le trasformazioni\n",
    "    def process_image(image_path):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "    # Funzione per calcolare l'accuratezza\n",
    "    def calculate_accuracy(predictions, targets):\n",
    "        correct = 0\n",
    "        total = len(targets)\n",
    "        for pred, target in zip(predictions, targets):\n",
    "            if pred == target:\n",
    "                correct += 1\n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "\n",
    "    # Carica il dispositivo (GPU se disponibile, altrimenti CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Carica il modello\n",
    "    model = load_model(model_path, device, num_classes)\n",
    "\n",
    "    # Leggi il CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Inizializza le liste per le predizioni e i target\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    # Itera attraverso i dati di test e fai previsioni\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Testing\"):\n",
    "        image_path = row['FilePath']  # Assicurati che il CSV abbia una colonna 'FilePath'\n",
    "        image = process_image(image_path).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_label = 'Target' if predicted.item() == 1 else 'Non-Target'  # Mappa l'output del modello alle etichette nel CSV\n",
    "\n",
    "        predictions.append(predicted_label)\n",
    "        targets.append(row['Label'])  # Assicurati che il CSV abbia una colonna 'Label' con 'Target' e 'Non-Target'\n",
    "\n",
    "    # Calcola l'accuratezza\n",
    "    accuracy = calculate_accuracy(predictions, targets)\n",
    "\n",
    "    # Stampa l'accuratezza\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T17:59:00.316374Z",
     "start_time": "2024-06-29T17:59:00.289298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model_alexnet(model_path, num_classes=2):\n",
    "    # Percorso al CSV (puoi definirlo qui)\n",
    "    csv_path = 'final_dataset/test/df_paths_test.csv'\n",
    "\n",
    "    # Funzione per caricare il modello\n",
    "    def load_model(model_path, device, num_classes):\n",
    "        model = models.alexnet(pretrained=True)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Modifica il classificatore finale\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    # Funzione per caricare un'immagine e applicare le trasformazioni\n",
    "    def process_image(image_path):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "    # Funzione per calcolare l'accuratezza\n",
    "    def calculate_accuracy(predictions, targets):\n",
    "        correct = 0\n",
    "        total = len(targets)\n",
    "        for pred, target in zip(predictions, targets):\n",
    "            if pred == target:\n",
    "                correct += 1\n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "\n",
    "    # Carica il dispositivo (GPU se disponibile, altrimenti CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Carica il modello\n",
    "    model = load_model(model_path, device, num_classes)\n",
    "\n",
    "    # Leggi il CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Inizializza le liste per le predizioni e i target\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    # Itera attraverso i dati di test e fai previsioni\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Testing\"):\n",
    "        image_path = row['FilePath']  # Assicurati che il CSV abbia una colonna 'FilePath'\n",
    "        image = process_image(image_path).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_label = 'Target' if predicted.item() == 1 else 'Non-Target'  # Mappa l'output del modello alle etichette nel CSV\n",
    "\n",
    "        predictions.append(predicted_label)\n",
    "        targets.append(row['Label'])  # Assicurati che il CSV abbia una colonna 'Label' con 'Target' e 'Non-Target'\n",
    "\n",
    "    # Calcola l'accuratezza\n",
    "    accuracy = calculate_accuracy(predictions, targets)\n",
    "\n",
    "    # Stampa l'accuratezza\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ],
   "id": "a94ef9bc50a9e1ef",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test primo modello GoogleNet",
   "id": "58192250017d29e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T16:09:16.395724Z",
     "start_time": "2024-06-29T15:53:26.363180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'models/test1_google_net/checkpoint_epoch_1.pt'\n",
    "test_model_google(model_path)"
   ],
   "id": "ed737b708b30c0a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Testing: 100%|██████████| 7689/7689 [15:49<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test secondo modello GoogleNet",
   "id": "c009f602f9c88e69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T16:24:40.993156Z",
     "start_time": "2024-06-29T16:09:16.399909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'models/test2_google_net/checkpoint_epoch_1.pt'\n",
    "test_model_google(model_path)"
   ],
   "id": "9f328f0542f75b91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Testing: 100%|██████████| 7689/7689 [15:24<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test terzo modello GoogleNet",
   "id": "f4a6b04cf20ef308"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T16:39:59.505020Z",
     "start_time": "2024-06-29T16:24:40.995158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'models/test3_google_net/checkpoint_epoch_1.pt'\n",
    "test_model_google(model_path)"
   ],
   "id": "e272337716d894c1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Testing: 100%|██████████| 7689/7689 [15:18<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test quarto modello GoogleNet",
   "id": "ab230fbc9ce6acfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T17:45:38.318047Z",
     "start_time": "2024-06-29T17:28:45.794472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'models/test4_google_net/checkpoint_epoch_1.pt'\n",
    "test_model_google(model_path)"
   ],
   "id": "f2fb4a9a86fb9819",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7689/7689 [16:52<00:00,  7.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test quinto modello AlexNet",
   "id": "60abb616dd46133d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T18:05:14.747490Z",
     "start_time": "2024-06-29T17:59:18.290517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'models/test5_alex_net/checkpoint_epoch_1.pt'\n",
    "test_model_alexnet(model_path)"
   ],
   "id": "90d5d26096acff60",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Testing: 100%|██████████| 7689/7689 [05:55<00:00, 21.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9870\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test sesto modello AlexNet",
   "id": "970eb41f02d5fd0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T18:07:32.055286Z",
     "start_time": "2024-06-29T18:07:30.663392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'models/test6_alex_net/checkpoint_epoch_1.pt'\n",
    "test_model_alexnet(model_path)"
   ],
   "id": "56e765f18217dfe8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gio22\\anaconda3\\envs\\bio\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/test6_alex_net/checkpoint_epoch_1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels/test6_alex_net/checkpoint_epoch_1.pt\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtest_model_alexnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 39\u001B[0m, in \u001B[0;36mtest_model_alexnet\u001B[1;34m(model_path, num_classes)\u001B[0m\n\u001B[0;32m     36\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Carica il modello\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Leggi il CSV\u001B[39;00m\n\u001B[0;32m     42\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(csv_path)\n",
      "Cell \u001B[1;32mIn[14], line 9\u001B[0m, in \u001B[0;36mtest_model_alexnet.<locals>.load_model\u001B[1;34m(model_path, device, num_classes)\u001B[0m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39malexnet(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mclassifier[\u001B[38;5;241m6\u001B[39m] \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(model\u001B[38;5;241m.\u001B[39mclassifier[\u001B[38;5;241m6\u001B[39m]\u001B[38;5;241m.\u001B[39min_features, num_classes)  \u001B[38;5;66;03m# Modifica il classificatore finale\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\bio\\lib\\site-packages\\torch\\serialization.py:997\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    995\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 997\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    998\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    999\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1001\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1002\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\bio\\lib\\site-packages\\torch\\serialization.py:444\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 444\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\bio\\lib\\site-packages\\torch\\serialization.py:425\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 425\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'models/test6_alex_net/checkpoint_epoch_1.pt'"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2badd2d83ea64a9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
